# ğŸš€ Projeto Integrado Deep Learning â€” Pipeline Atualizado

## ğŸ“‘ VisÃ£o Geral do Projeto

Este projeto tem como objetivo o desenvolvimento de um pipeline de Deep Learning aplicado Ã  anÃ¡lise de sÃ©ries temporais e imagens no mercado financeiro. O projeto combina dados tabulares com imagens geradas a partir de sÃ©ries histÃ³ricas de ativos, visando construir modelos preditivos robustos.

---

## ğŸ—ï¸ Arquitetura e Justificativa

### âœ”ï¸ VisÃ£o EstratÃ©gica da Arquitetura

Adotamos uma **arquitetura hÃ­brida**, que maximiza desempenho local para prÃ©-processamento e vetorizacÃ£o pesada, mantendo a escalabilidade e a conveniÃªncia da nuvem para treinamento e experimentos com GPU.

| Componente                        | LocalizaÃ§Ã£o           | Justificativa                                                                 |
| --------------------------------- | --------------------- | ----------------------------------------------------------------------------- |
| **Dados brutos (imagens + CSV)**  | Local (SSD Ubuntu)    | Alta performance no acesso e prÃ©-processamento local sem limitaÃ§Ã£o de volume. |
| **Dados tabulares processados**   | MongoDB Local         | Banco perene, controle total dos dados, rÃ¡pido, escalÃ¡vel e offline.          |
| **Vetores das imagens (X\_img)**  | MongoDB Local + Drive | PersistÃªncia local + backup/transferÃªncia via Drive para uso no Colab.        |
| **Arquivos para modelagem (X/y)** | Google Drive          | Acesso rÃ¡pido no Colab (GPU) para treinamento e experimentaÃ§Ã£o.               |

---

## ![Arquitetura](./images/arquitetura_pipeline.png)

---

## ğŸ”¥ Pipeline de Desenvolvimento

### ğŸ”„ Fluxo Completo

```plaintext
IngestÃ£o â†’ PersistÃªncia no MongoDB Local â†’ VetorizaÃ§Ã£o das Imagens â†’
ExportaÃ§Ã£o (Drive) â†’ Modelagem (Colab com GPU) â†’ ValidaÃ§Ã£o â†’ EDA PÃ³s-Modelagem
```

---

### ğŸš€ Etapas Detalhadas

| Etapa                                      | Status | DescriÃ§Ã£o                                                                                               |
| ------------------------------------------ | ------ | ------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£ **ConfiguraÃ§Ã£o do Ambiente Local**     | âœ…      | CriaÃ§Ã£o do ambiente em Ubuntu + MongoDB Local + Git + Estrutura de diretÃ³rios.                          |
| 2ï¸âƒ£ **IngestÃ£o dos Dados Brutos**          | âœ…      | CÃ³pia dos dados (imagens e CSVs) para SSD local.                                                        |
| 3ï¸âƒ£ **PersistÃªncia no MongoDB Local**      | âœ…      | Dados tabulares (treino/teste) e metadados das imagens sÃ£o armazenados no MongoDB Local.                |
| 4ï¸âƒ£ **VetorizaÃ§Ã£o das Imagens**            | âœ…      | ConversÃ£o das imagens em vetores numÃ©ricos de alta dimensÃ£o (CNN Encoder).                              |
| 5ï¸âƒ£ **PersistÃªncia dos Vetores**           | âœ…      | Vetores sÃ£o salvos no MongoDB Local e exportados como arquivos (.npy, .csv, .json) para o Google Drive. |
| 6ï¸âƒ£ **ConstruÃ§Ã£o dos Datasets Finais**     | ğŸš§     | CombinaÃ§Ã£o dos dados tabulares (X\_csv), vetores de imagem (X\_img) e labels (y).                       |
| 7ï¸âƒ£ **Modelagem (Deep Learning)**          | â³      | Desenvolvimento dos modelos CNN 1D, RNN (LSTM/GRU) e CNN 2D (imagens).                                  |
| 8ï¸âƒ£ **ValidaÃ§Ã£o e Ajustes dos Modelos**    | â³      | AvaliaÃ§Ã£o de mÃ©tricas, ajustes de hiperparÃ¢metros, combate a overfitting e anÃ¡lise de erros.            |
| 9ï¸âƒ£ **AnÃ¡lise ExploratÃ³ria PÃ³s-Modelagem** | â³      | EDA baseada nos resultados dos modelos para identificar padrÃµes, erros e melhorias potenciais.          |
| ğŸ”Ÿ **Backtest Financeiro (Opcional)**      | â³      | AvaliaÃ§Ã£o financeira simulada da estratÃ©gia gerada pelos modelos (retorno, drawdown, etc.).             |
| ğŸï¸ **DocumentaÃ§Ã£o Final e Entrega**       | â³      | Refinamento do README, notebooks finais, dashboards e apresentaÃ§Ã£o.                                     |

---

## ğŸ“‚ OrganizaÃ§Ã£o dos Dados

### ğŸ“ Estrutura Local

```plaintext
/workspace/DLProject/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Dados originais (imagens + CSV)
â”‚   â”œâ”€â”€ processed/    # Dados processados (vetores, datasets finais)
â”‚   â””â”€â”€ backups/      # Backups locais
â”œâ”€â”€ notebooks/        # Jupyter Notebooks
â”œâ”€â”€ scripts/          # Scripts Python (.py)
â”œâ”€â”€ models/           # Modelos treinados
â”œâ”€â”€ README.md         # DocumentaÃ§Ã£o
â””â”€â”€ requirements.txt  # DependÃªncias
```

### â˜ï¸ Estrutura no Google Drive

```plaintext
/DLProject/data/processed/VALE3/
â”œâ”€â”€ X_img.npy         # Vetores das imagens
â”œâ”€â”€ X_csv.npy         # Dados tabulares vetorizados
â”œâ”€â”€ y.npy             # Labels

/DLProject/data/processed/PETR4/
...

/DLProject/models/
â”œâ”€â”€ cnn1d_model.h5
â”œâ”€â”€ rnn_model.h5
â”œâ”€â”€ cnn2d_model.h5

/DLProject/reports/
â”œâ”€â”€ resultados.xlsx
â”œâ”€â”€ graficos.png
```

---

## âœ… Vantagens da Arquitetura

* ğŸï¸ **Desempenho local mÃ¡ximo:** Processamento pesado (vetorizaÃ§Ã£o, prÃ©-processamento) roda no SSD local, sem custos e sem limites.
* ğŸ”— **MongoDB Local:** Banco perene, controle total dos dados, rÃ¡pido, escalÃ¡vel e offline.
* â˜ï¸ **Drive como Hub de Modelagem:** Armazena datasets prontos para uso no Colab com GPU.
* ğŸ” **SeguranÃ§a e Controle:** Dados sensÃ­veis nÃ£o expostos na internet, mantidos no ambiente local.
* ğŸ’° **Zero custos adicionais:** Sem dependÃªncia de MongoDB Atlas ou outros serviÃ§os pagos para dados de alto volume.
* ğŸ”„ **Pipeline replicÃ¡vel e auditÃ¡vel:** Documentado, organizado e adequado tanto para uso acadÃªmico quanto profissional.

---

## ğŸš© PrÃ³ximos Passos Imediatos

1ï¸âƒ£ **Finalizar a construÃ§Ã£o dos datasets finais (X\_img + X\_csv + y).**
2ï¸âƒ£ **Subir para o Drive e configurar o notebook Colab para leitura.**
3ï¸âƒ£ **Iniciar a modelagem com CNN 1D, RNN e CNN 2D no Colab (com GPU).**
4ï¸âƒ£ **Realizar EDA PÃ³s-Modelagem e ajuste fino dos modelos.**
5ï¸âƒ£ **Documentar e gerar entrega final acadÃªmica e profissional.**

---

## ğŸ“œ CrÃ©ditos

* Projeto desenvolvido no contexto do **MBA em Deep Learning â€” FIAP**.
* Autor: **Wilson Melo**.
* OrientaÃ§Ã£o e apoio: Comunidade e Professores da FIAP.
